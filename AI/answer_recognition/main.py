from PIL import Image, ImageDraw
import cv2
import numpy as np
# from ultralytics import YOLO # ì‚­ì œ
import os
import json
from pathlib import Path
import shutil
from typing import Dict, List, Any, Tuple, Optional, TypedDict
# from transformers import pipeline # ì‚­ì œ
import re # ì‚­ì œ
from io import BytesIO
import base64

# config.pyë¡œë¶€í„° import
from .config import (
    YOLO_MODEL_PATH, YOLO_CLASS_QN, YOLO_CLASS_ANS, 
    yolo_model, mnist_recognition_pipeline, KEY_PARSING_REGEX
)

# data_structures.pyë¡œë¶€í„° import
from .data_structures import DetectedArea

# preprocessing/yolo_detector.pyë¡œë¶€í„° import
from .preprocessing.yolo_detector import yolo_predict_and_extract_areas_pil

# preprocessing/image_utils.pyë¡œë¶€í„° import
from .preprocessing.image_utils import (
    enhance_and_find_contours_for_lines,
    crop_between_lines,
    preprocess_line_image_for_text_contours,
    merge_contours_and_crop_text_pil
)

# recognition/digit_recognizer.pyë¡œë¶€í„° import
from .recognition.digit_recognizer import (
    pil_find_digit_contours_in_text_crop,
    pil_recognize_digits_from_bboxes,
    group_and_combine_digits
)

# utils/key_utils.pyë¡œë¶€í„° import
from .utils.key_utils import (
    create_question_info_dict,
    generate_final_key_for_ans_crop
)

# INTER_LINEARì´ ì—†ìœ¼ë©´ ëŒ€ì²´ê°’ ì§ì ‘ ì„¤ì • (ë³´í†µ 1)
if not hasattr(cv2, 'INTER_LINEAR'):
    cv2.INTER_LINEAR = 1

# --- Helper Functions ---

# --- Main Preprocessing Function ---
def preprocess_answer_sheet(
    original_image_path: str,
    answer_key_json_path: str,
) -> Dict[str, Image.Image]:
    final_ans_text_crop_dict: Dict[str, Image.Image] = {}
    if not Path(original_image_path).exists() or not Path(answer_key_json_path).exists():
        print(f"Error: Missing original image or answer key JSON. Image: {original_image_path}, Key: {answer_key_json_path}")
        return {}

    try:
        original_pil_image = Image.open(original_image_path).convert("RGB")
        with open(answer_key_json_path, 'r', encoding='utf-8') as f:
            answer_key_data = json.load(f)
    except Exception as e:
        print(f"Error opening files for preprocessing: {e}")
        return {}
        
    subject_name = Path(original_image_path).parent.name # ê³¼ëª©ëª… (ìƒìœ„ ë””ë ‰í† ë¦¬ëª…)
    student_id_filename_stem = Path(original_image_path).stem # í•™ë²ˆ (íŒŒì¼ëª…ì—ì„œ í™•ì¥ì ì œì™¸)
    subject_student_id_base = f"{subject_name}_{student_id_filename_stem}"
    
    print(f"Preprocessing: {subject_student_id_base} (from {original_image_path})")

    print("  ë‹¨ê³„ 1: YOLO detection...")
    qn_detected_area, ans_detected_area = yolo_predict_and_extract_areas_pil(original_pil_image, subject_student_id_base)

    if ans_detected_area is None:
        print(f"  ë‹µë³€ ì˜ì—­ì´ YOLOì—ì„œ ë°œê²¬ë˜ì§€ ì•ŠìŒ {subject_student_id_base}.")
        return {}
    if qn_detected_area is None:
        print(f"  ì§ˆë¬¸ ì˜ì—­ì´ YOLOì—ì„œ ë°œê²¬ë˜ì§€ ì•ŠìŒ {subject_student_id_base}.")
        return {}
    
    print("  ë‹¨ê³„ 2&3 (ì§ˆë¬¸ ì •ë³´ ë”•ì…”ë„ˆë¦¬ ìƒì„±)...")
    question_info_dict = create_question_info_dict([qn_detected_area], answer_key_data)
    # --- question_info_dict ì¶œë ¥ ë””ë²„ê·¸ ì½”ë“œ ì‹œì‘ ---
    print(f"  [Debug Main] ìƒì„±ëœ question_info_dict (í‚¤ ê°œìˆ˜: {len(question_info_dict)}):")
    # json.dumpsë¥¼ ì‚¬ìš©í•˜ì—¬ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥, í•œê¸€ ê¹¨ì§ ë°©ì§€ ensure_ascii=False
    # ë„ˆë¬´ ê¸¸ ê²½ìš° ì¼ë¶€ë§Œ ì¶œë ¥í•˜ê±°ë‚˜, íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” ê²ƒì„ ê³ ë ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    # ì—¬ê¸°ì„œëŠ” ì „ì²´ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
    try:
        print(json.dumps(question_info_dict, indent=2, ensure_ascii=False))
    except TypeError as e:
        # PIL Image ê°ì²´ ë“±ì´ ì§ì ‘ í¬í•¨ë˜ì–´ json.dumpsê°€ ì‹¤íŒ¨í•˜ëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„
        print(f"    question_info_dictë¥¼ JSONìœ¼ë¡œ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ (ì§ì ‘ ì¶œë ¥ ì‹œë„): {e}")
        print(question_info_dict) # ì´ ê²½ìš°, ì¼ë°˜ printë¡œ ì¶œë ¥
    # --- question_info_dict ì¶œë ¥ ë””ë²„ê·¸ ì½”ë“œ ë ---
    if not question_info_dict: 
        print(f"  ì§ˆë¬¸ ì •ë³´ ë”•ì…”ë„ˆë¦¬ ìƒì„± ì‹¤íŒ¨ {subject_student_id_base}. ì§ˆë¬¸ ë°œê²¬ ë° ë‹µë³€ í‚¤ ì¼ì¹˜ í™•ì¸ í•„ìš”.")
        return {}

    print("  ë‹¨ê³„ 4 & 5 (ë‹µë³€ ì˜ì—­ ì²˜ë¦¬ ë° í‚¤ ìƒì„±)...") # DEBUG KOR
    ans_area_idx = 0  # ë‹¨ì¼ ê°ì²´ì´ë¯€ë¡œ ì¸ë±ìŠ¤ë¥¼ 0ìœ¼ë¡œ ê³ ì •
    
    # ans_area_data ëŒ€ì‹  ans_detected_area (ë‹¨ì¼ ê°ì²´)ë¥¼ ì§ì ‘ ì‚¬ìš©
    ans_area_pil = ans_detected_area['image_obj'] # ans ì˜ì—­ì˜ PIL ì´ë¯¸ì§€ ê°ì²´
    ans_area_y_offset_orig = ans_detected_area['bbox'][1] # ì›ë³¸ ë‹µì•ˆì§€ ì´ë¯¸ì§€ ê¸°ì¤€ìœ¼ë¡œ ë‹µë³€ ì˜ì—­ì˜ y ì‹œì‘ ì˜¤í”„ì…‹.
    current_ans_area_id = f"ansArea{ans_area_idx}" # í•­ìƒ "ansArea0"

    # ë‹µë³€ ì˜ì—­ ë‚´ì—ì„œ ìˆ˜í‰ì„  ìœ¤ê³½ ì°¾ê¸° ë° ë¼ì¸ ë¶„ë¦¬
    line_contours = enhance_and_find_contours_for_lines(ans_area_pil) # ì´ í•¨ìˆ˜ì˜ ë°˜í™˜ ê°’ (ê°ì§€ëœ ìˆ˜í‰ì„ ë“¤ì˜ ê²½ê³„ ìƒì ë¦¬ìŠ¤íŠ¸)ì´ line_contoursì— í• ë‹¹ë©ë‹ˆë‹¤.
    line_cropped_ans_list = crop_between_lines(ans_area_pil, line_contours)
        # ans_area_pil (ë‹µë³€ ì˜ì—­ ì´ë¯¸ì§€)ê³¼ line_contours (ì°¾ì•„ë‚¸ ìˆ˜í‰ì„  ì •ë³´)ê°€ crop_between_lines í•¨ìˆ˜ì˜ ì¸ìë¡œ ì „ë‹¬ë©ë‹ˆë‹¤.
        # ì´ í•¨ìˆ˜ì˜ ë°˜í™˜ ê°’ (ì˜ë¦° ê° ë¼ì¸ ì´ë¯¸ì§€ì™€ í•´ë‹¹ ë¼ì¸ì˜ yì¢Œí‘œ ì •ë³´ë¥¼ ë‹´ì€ ë”•ì…”ë„ˆë¦¬ë“¤ì˜ ë¦¬ìŠ¤íŠ¸)ì´ line_cropped_ans_listì— í• ë‹¹ë©ë‹ˆë‹¤.

    # ì´ ë£¨í”„ëŠ” line_cropped_ans_listì— ìˆëŠ” ê° ë¼ì¸ ì¡°ê°ì— ëŒ€í•´ ë°˜ë³µë©ë‹ˆë‹¤. 
    # line_idxëŠ” í˜„ì¬ ë¼ì¸ì˜ ì¸ë±ìŠ¤, line_crop_dataëŠ” í˜„ì¬ ë¼ì¸ ì´ë¯¸ì§€ì™€ yì •ë³´ë¥¼ ë‹´ì€ ë”•ì…”ë„ˆë¦¬ì…ë‹ˆë‹¤.
    for line_idx, line_crop_data in enumerate(line_cropped_ans_list):
        line_ans_pil = line_crop_data['image_obj']

        line_y_top_in_ans_area = line_crop_data['y_top_in_area']
        current_line_id = f"{line_idx}" # ì‹¤ì œ current_line_idëŠ” ì—¬ê¸°ì„œ í• ë‹¹ë¨ (í‚¤ ìƒì„± ë“±ì— ì‚¬ìš©)

        # ë¼ì¸ ë‚´ í…ìŠ¤íŠ¸ ì»¨íˆ¬ì–´(ìœ¤ê³½ì„ ) ê²€ì¶œ
        text_contours_cv = preprocess_line_image_for_text_contours(line_ans_pil)
        # í…ìŠ¤íŠ¸ ì»¨íˆ¬ì–´ ë³‘í•© ë° ê°œë³„ í…ìŠ¤íŠ¸ ì´ë¯¸ì§€ ì¶”ì¶œ
        final_ans_text_crops_in_line = merge_contours_and_crop_text_pil(line_ans_pil, text_contours_cv) # horizontally_crop_image -> text_crop images
        
        # ê°œë³„ í…ìŠ¤íŠ¸ ì¡°ê°(text crop) ì²˜ë¦¬ ë£¨í”„
        for text_idx, text_crop_data_in_line in enumerate(final_ans_text_crops_in_line):
            ans_text_crop_pil = text_crop_data_in_line['image_obj']
            
            ans_text_crop_full_info = {
                'image_obj': ans_text_crop_pil,  # ìµœì¢…ì ìœ¼ë¡œ ì˜ë¦° ê°œë³„ í…ìŠ¤íŠ¸ ì¡°ê°ì˜ PIL Image ê°ì²´
                'x_in_line': text_crop_data_in_line['x_in_line'], # í˜„ì¬ ë¼ì¸(line_ans_pil) ë‚´ì—ì„œ ì´ í…ìŠ¤íŠ¸ ì¡°ê°ì˜ ì‹œì‘ x ì¢Œí‘œ
                'y_in_line_relative_to_line_crop_top': text_crop_data_in_line['y_in_line'], # í˜„ì¬ ë¼ì¸(line_ans_pil)ì˜ ìƒë‹¨ ê¸°ì¤€ìœ¼ë¡œ ì´ í…ìŠ¤íŠ¸ ì¡°ê°ì˜ ì‹œì‘ y ì¢Œí‘œ -> í•„ìš” ì—†ì–´ë³´ì„
                'line_y_top_relative_to_ans_area': line_y_top_in_ans_area, # ì „ì²´ ë‹µë³€ ì˜ì—­(ans_area_pil) ë‚´ì—ì„œ í˜„ì¬ ë¼ì¸ì˜ ì‹œì‘ y ì¢Œí‘œ
                'ans_area_y_offset_orig': ans_area_y_offset_orig, # ì›ë³¸ ë‹µì•ˆì§€ ì´ë¯¸ì§€ì—ì„œ ì „ì²´ ë‹µë³€ ì˜ì—­(ans_area_pil)ì˜ ì‹œì‘ y ì˜¤í”„ì…‹
                # 'ans_area_id': current_ans_area_id, # ì œê±°ë¨ (ì´ì „ì— ì‚¬ìš©ë˜ì—ˆë˜ ì „ì²´ ë‹µë³€ ì˜ì—­ì˜ ID)
                'line_id_in_ans_area': current_line_id # í˜„ì¬ ë¼ì¸ì˜ ID (ì˜ˆ: "L0", "L1")
            }
            
            final_key_base = generate_final_key_for_ans_crop(
                subject_student_id_base, # ê³¼ëª©ëª…_í•™ë²ˆ ì „ë‹¬
                ans_text_crop_full_info,
                question_info_dict,
                answer_key_data
            )
            # (ì—¬ê¸°)
            temp_key = final_key_base
            key_suffix = 0
            while temp_key in final_ans_text_crop_dict:
                key_suffix += 1
                temp_key = f"{final_key_base}_dup{key_suffix}"
            final_key = temp_key
            final_ans_text_crop_dict[final_key] = ans_text_crop_pil

    
    print(f"  ì „ì²˜ë¦¬ ì™„ë£Œ: {subject_student_id_base}. ì´ {len(final_ans_text_crop_dict)}ê°œì˜ ì˜ë¦° ë‹µë³€ í…ìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„±ë¨.") # DEBUG KOR
    return final_ans_text_crop_dict






def recognize_answer_sheet_data(
    processed_ans_crops: Dict[str, Image.Image], # preprocess_answer_sheet í•¨ìˆ˜ì˜ ë°˜í™˜ ê°’
    answer_key_data: Dict[str, Any]
) -> Dict[str, Any]:
    """
    ì „ì²˜ë¦¬ëœ ë‹µì•ˆ í…ìŠ¤íŠ¸ ì¡°ê° ì´ë¯¸ì§€ë“¤ë¡œë¶€í„° ìˆ«ìë¥¼ ì¸ì‹í•˜ì—¬
    ìµœì¢…ì ìœ¼ë¡œ answer_json ë° failure_jsonì„ ìƒì„±í•©ë‹ˆë‹¤.

    Returns:
        Dict[str, Any]: answer_jsonê³¼ failure_jsonì„ í¬í•¨í•˜ëŠ” ë”•ì…”ë„ˆë¦¬.
    """
    import re # Moved here
    from collections import defaultdict # Moved here
    
    # --- 0ë‹¨ê³„: ì´ˆê¸° ìœ íš¨ì„± ê²€ì¦ ë° ê¸°ë³¸ ì •ë³´ íŒŒì‹± ---
    # ì…ë ¥ìœ¼ë¡œ ë°›ì€ processed_ans_cropsê°€ ë¹„ì–´ ìˆëŠ” ê²½ìš°, ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•˜ê³  ë¹ˆ ê²°ê³¼ë¥¼ ë°˜í™˜ (early return)
    # processed_ans_cropsì˜ ì²« ë²ˆì§¸ keyë¥¼ ìƒ˜í”Œë¡œ ì‚¬ìš©í•˜ì—¬ ì•„ë˜ ì •ë³´ë¥¼ íŒŒì‹±:
        # í•™ë²ˆ(student_id): key ë‚´ 8ìë¦¬ ìˆ«ìë¥¼ ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ì¶”ì¶œ
        # ê³¼ëª©ëª…(subject): key ë‚´ì—ì„œ í•™ë²ˆ ì•ê¹Œì§€ì˜ ë¬¸ìì—´ ì¤‘ ë§ˆì§€ë§‰ '_'ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•™ë²ˆ ì œì™¸
    # ì´í›„ ë‹¨ê³„ì—ì„œ ì‚¬ìš©í•  ê²°ê³¼ ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬ answer_result / failure_result ì´ˆê¸°í™”

    if not processed_ans_crops:
        print("[Error] ì…ë ¥ëœ processed_ans_cropsê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
        return {
            "answer_json": {},
            "failure_json": {}
        }

    # ì²« ë²ˆì§¸ í‚¤ í•˜ë‚˜ë¥¼ ìƒ˜í”Œë¡œ ì¶”ì¶œí•˜ì—¬ subjectì™€ student_id íŒŒì‹±
    sample_key = next(iter(processed_ans_crops))
    try:
        # ì˜ˆì‹œ í‚¤: test_answer_32174515_LL1_x60_qn1_ac0
        student_id_match = re.search(r"\d{8}", sample_key)
        if not student_id_match:
            raise ValueError("í•™ë²ˆ(8ìë¦¬ ìˆ«ì)ì„ keyì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        student_id = student_id_match.group()
        subject_with_id = sample_key[:sample_key.find(student_id) + len(student_id)]
        subject = subject_with_id.rsplit("_", 1)[0]

        print(f"[Init] íŒŒì‹±ëœ subject: {subject}, student_id: {student_id}")
    except Exception as e:
        print(f"[Error] Key íŒŒì‹± ì‹¤íŒ¨ - ì˜ˆì™¸: {e}")
        return {
            "answer_json": {},
            "failure_json": {}
        }

    # ê²°ê³¼ ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬ ì´ˆê¸°í™”
    answer_result: Dict[str, Dict[str, Any]] = {}
    failure_result: Dict[str, List[Dict[str, Any]]] = {}

    # --- 0ë‹¨ê³„ í™•ì¸ì„ ìœ„í•œ ì„ì‹œ ë°˜í™˜ ---
    # return {
    #     "parsed_subject": subject,
    #     "parsed_student_id": student_id,
    #     "initial_answer_result": answer_result,
    #     "initial_failure_result": failure_result,
    #     "message": "0ë‹¨ê³„ (ì´ˆê¸°í™” ë° íŒŒì‹±) í…ŒìŠ¤íŠ¸ ì™„ë£Œ"
    # }









    # --- 1ë‹¨ê³„: ì´ë¯¸ì§€ ê·¸ë£¹í•‘ ë° ì¢Œí‘œ íŒŒì‹± ---
    # â€¢ processed_ans_cropsì˜ keyë¥¼ ìˆœíšŒí•˜ë©° question number(qn)ë¥¼ ì¶”ì¶œ
    # â€¢ key ë‚´ë¶€ì—ì„œ x, y ì¢Œí‘œë„ ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ì¶”ì¶œ
    # â€¢ qn ê°’ì´ ì—†ì„ ê²½ìš° unknownQNìœ¼ë¡œ ì²˜ë¦¬
    # â€¢ ê° qnì— ëŒ€í•´ ë¦¬ìŠ¤íŠ¸ ìƒì„±: { key, img, x, y } ë”•ì…”ë„ˆë¦¬ ì¶”ê°€
    # â€¢ ê° qn ë¦¬ìŠ¤íŠ¸ ë‚´ ê°ì²´ë“¤ì„ y ì˜¤ë¦„ì°¨ìˆœ â†’ x ì˜¤ë¦„ì°¨ìˆœìœ¼ë¡œ ì •ë ¬
    import re
    from collections import defaultdict
    from sklearn.cluster import KMeans
    import numpy as np

    def extract_tail_question_counts(answer_key_data: dict) -> dict:
        """
        answer_key_dataë¡œë¶€í„° ê° ë¬¸ì œ(qn)ì˜ ê¼¬ë¦¬ë¬¸ì œ ê°œìˆ˜(sub_question_numberì˜ ê°œìˆ˜)ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.

        Returns:
            tail_question_counts: Dict[str, int]
                ì˜ˆ: {"1": 28, "2": 1, "3": 1, ...}
        """
        tail_question_counts = defaultdict(int)

        for q in answer_key_data.get("questions", []):
            qn = str(q["question_number"])
            tail_question_counts[qn] += 1

        return dict(tail_question_counts)
    
    

    # --- 1ë‹¨ê³„: ë¬¸ì œ ë²ˆí˜¸(qn) ê¸°ì¤€ìœ¼ë¡œ ê·¸ë£¹í•‘ ë° ì¢Œí‘œ ì •ë ¬ ---
    # â€¢ processed_ans_cropsì˜ ê° keyì—ì„œ ë¬¸ì œ ë²ˆí˜¸(qn), x, y ì¢Œí‘œë¥¼ íŒŒì‹±
    # â€¢ ê° qnë³„ë¡œ ì´ë¯¸ì§€ë“¤ì„ ëª¨ì•„ì„œ grouped_answers_by_qnì— ì €ì¥
    # â€¢ ì´ë•Œ (x, y) ì¢Œí‘œ ì •ë³´ë¥¼ í•¨ê»˜ í¬í•¨ì‹œì¼œ ì¶”í›„ ì •ë ¬/í´ëŸ¬ìŠ¤í„°ë§ì— ì‚¬ìš©
    # â€¢ tail_question_countsë¥¼ ê¸°ë°˜ìœ¼ë¡œ y ê¸°ì¤€ KMeans í´ëŸ¬ìŠ¤í„°ë§ì´ í•„ìš”í•œ ë¬¸ì œë¥¼ ì‹ë³„í•¨


    grouped_answers_by_qn = {}


    for key, img in processed_ans_crops.items():
        # 1. ë¬¸ì œ ë²ˆí˜¸ íŒŒì‹± (qn)
        qn_match = re.search(r'_qn([a-zA-Z0-9\-]+)', key)
        qn = qn_match.group(1) if qn_match else "unknownQN"

        # ì¢Œí‘œ íŒŒì‹±
        x_match = re.search(r'_x(\d+)', key)
        y_match = re.search(r'_y(\d+)', key)
        x = int(x_match.group(1)) if x_match else -1
        y = int(y_match.group(1)) if y_match else -1

        entry = {
            "key": key,
            "img": img,
            "x": x,
            "y": y
        }
        
        # unknownQNì¸ ê²½ìš° ê²½ê³  ë©”ì‹œì§€ ì¶œë ¥í•˜ê³  ê±´ë„ˆë›°ê¸°
        if qn == "unknownQN":
            print(f"[Warning] Key '{key}'ì—ì„œ ìœ íš¨í•œ ë¬¸ì œ ë²ˆí˜¸(qn)ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
            continue
            
        # 2. ë¬¸ì œ ë‹¨ìœ„ ê·¸ë£¹í•‘
        if qn not in grouped_answers_by_qn:
            grouped_answers_by_qn[qn] = []

        grouped_answers_by_qn[qn].append(entry)

    # 3. qn - sub_qn í• ë‹¹
    # ì´ì œ ê° qnì— ëŒ€í•´ y ì •ë ¬ ë˜ëŠ” KMeans í´ëŸ¬ìŠ¤í„°ë§ì„ ì ìš©í•´ sub_qn í• ë‹¹
    grouped_answers_by_qn_and_subqn = {}
    tail_question_counts = extract_tail_question_counts(answer_key_data)
    '''
    tail_question_counts ì˜ˆì‹œ:
    {
        "1": 28,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        ...
    }
    '''

    # 3-1. ì‹œí—˜ì§€ ìœ í˜•1: ê¼¬ë¦¬ë¬¸ì œê°€ ì—†ëŠ” ê²½ìš°
        # x ê¸°ì¤€ ì •ë ¬ë§Œ ìˆ˜í–‰í•œë‹¤.
        # ì™œëƒí•˜ë©´ ê° qnì—ëŠ” ê¼¬ë¦¬ë¬¸ì œê°€ ì—†ìœ¼ë¯€ë¡œ, y ê¸°ì¤€ ì •ë ¬ì€ ë¶ˆí•„ìš”í•˜ê¸° ë•Œë¬¸ì´ë‹¤.
    if all(value == 1 for value in tail_question_counts.values()):
        for qn, entries in grouped_answers_by_qn.items():
            # ê¼¬ë¦¬ë¬¸ì œê°€ ì—†ëŠ” ê²½ìš°: qnë§Œ ì‚¬ìš©í•˜ì—¬ x ê¸°ì¤€ ì •ë ¬
            for idx, entry in enumerate(sorted(entries, key=lambda e: e["x"])):
                full_qn = qn  # sub_qn ì—†ìŒ

                if full_qn not in grouped_answers_by_qn_and_subqn:
                    grouped_answers_by_qn_and_subqn[full_qn] = []

                grouped_answers_by_qn_and_subqn[full_qn].append(entry)


    # 3-2. ì‹œí—˜ì§€ ìœ í˜•2: ê¼¬ë¦¬ë¬¸ì œê°€ ìˆê³  qnì— í¬í•¨ë˜ëŠ” ê²½ìš° - ì‹ í˜¸ì™€ ì‹œìŠ¤í…œ ì‹œí—˜ì§€ ìœ í˜•
        # ì‹ í˜¸ì™€ ì‹œìŠ¤í…œ ì‹œí—˜ì§€ì˜ ê²½ìš° ê¼¬ë¦¬ë¬¸ì œê°€ ìˆê³  qnì— í¬í•¨ëœë‹¤.
        # ì´ëŸ° ê²½ìš° 'ì‹œí—˜ì§€ ìœ í˜•1'ê³¼ ë™ì¼í•˜ê²Œ ì²˜ë¦¬í•œë‹¤.
        # ì°¸ê³ ë¡œ '2(a)', '7(b)'ì™€ ê°™ì€ ê¼¬ë¦¬ë¬¸ì œ í˜•ì‹ì´ì–´ë„ qnì€ í•­ìƒ '2-1', '7-2'ê³¼ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ì²˜ë¦¬ëœë‹¤.(ì´ëŠ” preprocess_answer_sheet í•¨ìˆ˜ì™€ ë‹µì§€.jsonì—ì„œ í™•ì¸í•  ìˆ˜ ìˆë‹¤.)
    elif any('-' in key for key in grouped_answers_by_qn.keys()):
        for qn, entries in grouped_answers_by_qn.items():
            # ê¼¬ë¦¬ë¬¸ì œê°€ ì—†ëŠ” ê²½ìš°: qnë§Œ ì‚¬ìš©í•˜ì—¬ x ê¸°ì¤€ ì •ë ¬
            for idx, entry in enumerate(sorted(entries, key=lambda e: e["x"])):
                full_qn = qn  # sub_qn ì—†ìŒ

                if full_qn not in grouped_answers_by_qn_and_subqn:
                    grouped_answers_by_qn_and_subqn[full_qn] = []

                grouped_answers_by_qn_and_subqn[full_qn].append(entry)


    # 3-3. ì‹œí—˜ì§€ ìœ í˜•3: ê¼¬ë¦¬ë¬¸ì œê°€ ìˆê³  qnì— í¬í•¨ë˜ì§€ ì•ŠëŠ” ê²½ìš° - ì¸ê³µì§€ëŠ¥ ì‹œí—˜ì§€ ìœ í˜•
        # ì¸ê³µì§€ëŠ¥ ì‹œí—˜ì§€ì˜ 1ë²ˆ ë¬¸ì œì˜ ê²½ìš° ê¼¬ë¦¬ë¬¸ì œê°€ ìˆê³  qn_yolo_area(yolo ê²€ì¶œ ê¸°ì¤€)ì— ê¼¬ë¦¬ë¬¸ì œê°€ í¬í•¨ë˜ì§€ ì•ŠëŠ”ë‹¤.
        # ì´ëŸ° ê²½ìš° ê¼¬ë¦¬ë¬¸ì œê°€ ìˆëŠ” ë¬¸ì œì— ëŒ€í•´ í…ìŠ¤íŠ¸ í¬ë¡­ ì´ë¯¸ì§€ë“¤ì„ y ê¸°ì¤€ ì •ë ¬í•œë‹¤.
        # ê·¸ í›„ ê¼¬ë¦¬ë¬¸ì œ ê°œìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ KMeans í´ëŸ¬ìŠ¤í„°ë§ì„ ìˆ˜í–‰í•œë‹¤.
    else:
        for qn, entries in grouped_answers_by_qn.items():
            entries_sorted = sorted(entries, key=lambda e: e["y"])

            if qn in tail_question_counts and tail_question_counts[qn] > 1:
                # ì–´ë–¤ ì£¼ ë¬¸ì œì˜ ê¼¬ë¦¬ë¬¸ì œê°€ ì—¬ëŸ¬ ê°œì¸ ê²½ìš°: y ê¸°ì¤€ KMeans í´ëŸ¬ìŠ¤í„°ë§ ì‚¬ìš©

                k = tail_question_counts[qn]
                y_values = np.array([e["y"] for e in entries_sorted]).reshape(-1, 1)

                try:
                    kmeans = KMeans(n_clusters=k, random_state=0, n_init="auto")
                    cluster_labels = kmeans.fit_predict(y_values)

                    # ì¤‘ì‹¬ yê°’ ê¸°ì¤€ìœ¼ë¡œ sub_qn ì¬ì •ë ¬
                    cluster_centers = kmeans.cluster_centers_.flatten()
                    sorted_cluster_indices = np.argsort(cluster_centers)
                    cluster_to_subqn = {cluster_idx: sub_qn + 1 for sub_qn, cluster_idx in enumerate(sorted_cluster_indices)}

                except Exception as e:
                    print(f"[Error] qn {qn} KMeans ì‹¤íŒ¨: {e}")
                    cluster_labels = list(range(len(entries_sorted)))
                    cluster_to_subqn = {i: i + 1 for i in range(len(entries_sorted))}

                for idx, entry in enumerate(entries_sorted):
                    cluster_idx = cluster_labels[idx]
                    sub_qn = cluster_to_subqn[cluster_idx]
                    full_qn = f"{qn}-{sub_qn}"

                    if full_qn not in grouped_answers_by_qn_and_subqn:
                        grouped_answers_by_qn_and_subqn[full_qn] = []
                    grouped_answers_by_qn_and_subqn[full_qn].append(entry)

            else:
                for idx, entry in enumerate(sorted(entries_sorted, key=lambda e: e["x"])):
                    full_qn = qn
                    if full_qn not in grouped_answers_by_qn_and_subqn:
                        grouped_answers_by_qn_and_subqn[full_qn] = []
                    grouped_answers_by_qn_and_subqn[full_qn].append(entry)

    # 4. full_qn ê¸°ì¤€ìœ¼ë¡œ grouped_answers_by_qn_and_subqn ì •ë ¬
        # full_qnì´ '1-2'ì™€ ê°™ì´ ê¼¬ë¦¬ë¬¸ì œë¥¼ í¬í•¨í•˜ëŠ” ê²½ìš°ë¥¼ ê³ ë ¤í•´ ì •ë ¬ë˜ë„ë¡ keyë¥¼ float ê°’ìœ¼ë¡œ ë³€í™˜
        # ì˜ˆ: '1-2' â†’ 1.02, '2' â†’ 2.00ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë²ˆí˜¸ ìˆœ ì •ë ¬ì„ ìì—°ìŠ¤ëŸ½ê²Œ ìˆ˜í–‰
    def qn_sort_key(qn_str):
        if '-' in qn_str:
            major, minor = qn_str.split('-')
            return float(f"{int(major)}.{int(minor):02d}")
        else:
            return float(f"{int(qn_str)}.00")

    grouped_answers_by_qn_and_subqn = dict(
        sorted(grouped_answers_by_qn_and_subqn.items(), key=lambda x: qn_sort_key(x[0]))
    )

    # --- í…ìŠ¤íŠ¸ í¬ë¡­ ì´ë¯¸ì§€ ì €ì¥ (ë””ë²„ê·¸) ---
    # ë””ë ‰í† ë¦¬ êµ¬ì¡°: {ê³¼ëª©ëª…}/{í•™ë²ˆ}/{full_qn}/{img}
    debug_output_dir = Path("debug_text_crops")
    subject_dir = debug_output_dir / subject
    student_dir = subject_dir / student_id
    
    try:
        student_dir.mkdir(parents=True, exist_ok=True)
        print(f"[Debug] ë””ë²„ê·¸ ì´ë¯¸ì§€ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±: {student_dir}")
        
        total_saved = 0
        for full_qn, entries in grouped_answers_by_qn_and_subqn.items():
            qn_dir = student_dir / full_qn
            qn_dir.mkdir(exist_ok=True)
            
            for idx, entry in enumerate(entries):
                img_obj = entry["img"]
                img_filename = f"{entry['key']}.png"
                img_path = qn_dir / img_filename
                
                if hasattr(img_obj, 'save'):
                    img_obj.save(str(img_path))
                    total_saved += 1
                else:
                    print(f"[Warning] Image object at {full_qn}[{idx}] is not a valid PIL Image")
        
        print(f"[Debug] ì´ {total_saved}ê°œì˜ í…ìŠ¤íŠ¸ í¬ë¡­ ì´ë¯¸ì§€ê°€ {student_dir}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
    except Exception as e:
        print(f"[Error] ë””ë²„ê·¸ ì´ë¯¸ì§€ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")




    # --- 1ë‹¨ê³„ í™•ì¸ì„ ìœ„í•œ ì„ì‹œ ë°˜í™˜ ---
    # grouped_answers_by_qn_and_subqnì„ ì§ë ¬í™”í•©ë‹ˆë‹¤.
    # ê° ë”•ì…”ë„ˆë¦¬ ë‚´ë¶€ì˜ 'img' PIL Image ê°ì²´ë¥¼ í¬ê¸° ì •ë³´ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.
    # grouped_answers_serializable = {}
    # for full_qn, entries in grouped_answers_by_qn_and_subqn.items():
    #     serializable_entries = []
    #     for entry in entries:
    #         serializable_entry = entry.copy() # ì›ë³¸ entry ìˆ˜ì •ì„ í”¼í•˜ê¸° ìœ„í•´ ë³µì‚¬
    #         img_obj = serializable_entry.pop("img") # img ê°ì²´ë¥¼ êº¼ë‚´ê³  entryì—ì„œ ì œê±°
    #         serializable_entry["img_size"] = img_obj.size if hasattr(img_obj, 'size') else 'N/A'
    #         serializable_entries.append(serializable_entry)
    #     grouped_answers_serializable[full_qn] = serializable_entries
    
    # return {
    #     "parsed_subject": subject,
    #     "parsed_student_id": student_id,
    #     "grouped_answers_by_qn_and_subqn": grouped_answers_serializable, # ì§ë ¬í™”ëœ ìƒˆ ë³€ìˆ˜ ì‚¬ìš© ë° í‚¤ ë³€ê²½
    #     "message": "1ë‹¨ê³„ (ì´ë¯¸ì§€ ê·¸ë£¹í•‘ ë° sub_qn í• ë‹¹) í…ŒìŠ¤íŠ¸ ì™„ë£Œ" # ë©”ì‹œì§€ ì—…ë°ì´íŠ¸
    # }











    # --- 2ë‹¨ê³„: ê°œë³„ ì´ë¯¸ì§€ì— ëŒ€í•œ ìˆ«ì ì¸ì‹ ìˆ˜í–‰ ---
    # â€¢ ì´ë¯¸ì§€ ë‚´ ìˆ«ì ì»¨íˆ¬ì–´ ê²€ì¶œ
    # â€¢ ì»¨íˆ¬ì–´ ê¸°ë°˜ìœ¼ë¡œ ìˆ«ì ë°•ìŠ¤ ì¶”ì¶œ
    # â€¢ ëª¨ë¸ì„ í†µí•´ ê° ìˆ«ì ë°•ìŠ¤ì— ëŒ€í•´ ìˆ«ì ì¸ì‹ ìˆ˜í–‰
    # â€¢ ì¸ì‹ëœ ìˆ«ìë¥¼ ì¡°í•©í•˜ì—¬ ìµœì¢… ë‹µì•ˆ ë¬¸ìì—´ ìƒì„±

    print("\n--- 2ë‹¨ê³„: ê°œë³„ ì´ë¯¸ì§€ì— ëŒ€í•œ ìˆ«ì ì¸ì‹ ìˆ˜í–‰ ì‹œì‘ ---")

    # 1. answer_key_data ê¸°ë°˜ ì´ˆê¸°í™”
    print("1. answer_key_data ê¸°ë°˜ ì´ˆê¸°í™” ì¤‘...")
    answer_json_studentAnswers = {
        "student_id": student_id,
        "answers": [
            {
                "question_number": entry["question_number"],
                "sub_question_number": entry["sub_question_number"],
                "student_answer": ""
            }
            for entry in answer_key_data.get("questions", [])
        ]
    }
    
    print(f"   ì´ˆê¸°í™”ëœ answer_json_studentAnswers (ë‹µì•ˆ ê°œìˆ˜: {len(answer_json_studentAnswers['answers'])}ê°œ):")
    for i, answer in enumerate(answer_json_studentAnswers['answers'][:5]):  # ì²˜ìŒ 5ê°œë§Œ ì¶œë ¥
        print(f"     [{i}] Q{answer['question_number']}-{answer['sub_question_number']}: '{answer['student_answer']}'")
    if len(answer_json_studentAnswers['answers']) > 5:
        print(f"     ... (ì´ {len(answer_json_studentAnswers['answers'])}ê°œ)")

    failure_json_images = []
    print(f"   failure_json_images ì´ˆê¸°í™” ì™„ë£Œ\n")

    # ê° full_qnì— ëŒ€í•´ ì²˜ë¦¬
    total_digit_crops_count = 0
    for idx, (full_qn, entries) in enumerate(grouped_answers_by_qn_and_subqn.items()):
        print(f"--- ì²˜ë¦¬ ì¤‘: {full_qn} (ì´ë¯¸ì§€ {len(entries)}ê°œ) ---")
        entries_sorted = sorted(entries, key=lambda e: e["x"])

        # 2. qn, sub_qn íŒŒì‹±
        if '-' in full_qn:
            qn, sub_qn = map(int, full_qn.split('-'))
        else:
            qn = int(full_qn)
            sub_qn = 1

        ac_match = re.search(r'_ac(\d+)', entries_sorted[0]['key'])
        ac = int(ac_match.group(1)) if ac_match else 1

        print(f"2. íŒŒì‹± ê²°ê³¼: qn={qn}, sub_qn={sub_qn}, ac={ac}")
        print(f"   ì •ë ¬ëœ ì´ë¯¸ì§€ë“¤ì˜ xì¢Œí‘œ: {[e['x'] for e in entries_sorted]}")

        digit_crops = []

        # 3. ì´ë¯¸ì§€ë¡œë¶€í„° ìˆ«ì ì»¨íˆ¬ì–´ ì¶”ì¶œ ë° ì¤‘ì‹¬ ì¢Œí‘œ ê³„ì‚°
        print("3. ìˆ«ì ì»¨íˆ¬ì–´ ì¶”ì¶œ ë° ì¤‘ì‹¬ ì¢Œí‘œ ê³„ì‚° ì¤‘...")
        for entry_idx, entry in enumerate(entries_sorted):
            pil_img = entry['img'].convert('L')
            np_img = np.array(pil_img)
            _, thresh = cv2.threshold(np_img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
            contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

            entry_digit_count = 0
            for cnt in contours:
                x, y, w, h = cv2.boundingRect(cnt)
                if h < 5 or w < 5:
                    continue
                crop = pil_img.crop((x, y, x + w, y + h))
                xc, yc = x + w // 2, y + h // 2
                digit_crops.append((crop, (xc, yc)))
                entry_digit_count += 1

            print(f"   ì´ë¯¸ì§€ [{entry_idx}] (key: {entry['key'][:50]}...): {entry_digit_count}ê°œ ìˆ«ì ì»¨íˆ¬ì–´ ë°œê²¬")

        print(f"   {full_qn} ì´ ìˆ«ì ì»¨íˆ¬ì–´: {len(digit_crops)}ê°œ")
        total_digit_crops_count += len(digit_crops)
        
        if digit_crops:
            print(f"   ì¤‘ì‹¬ ì¢Œí‘œ ìƒ˜í”Œ (ì²˜ìŒ 3ê°œ): {[coord for _, coord in digit_crops[:3]]}")
        else:
            print("   âš ï¸  ìˆ«ì ì»¨íˆ¬ì–´ê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")

        if not digit_crops:
            continue

        # ë‚˜ë¨¸ì§€ ë¶€ë¶„ë“¤ì€ ì£¼ì„ì²˜ë¦¬
        '''
        # 4. ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê¸°ë°˜ìœ¼ë¡œ ac-1ê°œì˜ split ì¸ë±ìŠ¤ ê²°ì •
        ac_splits = ac - 1
        if ac_splits > 0:
            centers_sorted = sorted(digit_crops, key=lambda t: t[1][0])
            distances = [np.linalg.norm(np.array(centers_sorted[i+1][1]) - np.array(centers_sorted[i][1]))
                        for i in range(len(centers_sorted) - 1)]
            split_indices = np.argsort(distances)[-ac_splits:]
            split_indices = sorted(split_indices)
        else:
            split_indices = []

        # 5. split index ê¸°ì¤€ìœ¼ë¡œ ìˆ«ì ê·¸ë£¹í•‘
        digits_grouped = []
        temp_group = []
        for i, (img, _) in enumerate(sorted(digit_crops, key=lambda t: t[1][0])):
            temp_group.append(img)
            if i in split_indices:
                digits_grouped.append(temp_group)
                temp_group = []
        if temp_group:
            digits_grouped.append(temp_group)
        '''

        # 4. ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê¸°ë°˜ìœ¼ë¡œ ac-1ê°œì˜ split ì¸ë±ìŠ¤ ê²°ì •
        print("4. ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê¸°ë°˜ split ì¸ë±ìŠ¤ ê²°ì • ì¤‘...")
        ac_splits = ac - 1
        if ac_splits > 0:
            centers_sorted = sorted(digit_crops, key=lambda t: t[1][0])
            distances = [np.linalg.norm(np.array(centers_sorted[i+1][1]) - np.array(centers_sorted[i][1]))
                        for i in range(len(centers_sorted) - 1)]
            split_indices = np.argsort(distances)[-ac_splits:]
            split_indices = sorted(split_indices)
            print(f"   ac={ac}, ac_splits={ac_splits}")
            print(f"   ì¤‘ì‹¬ ì¢Œí‘œ ì •ë ¬ëœ ìˆœì„œ: {[coord for _, coord in centers_sorted]}")
            print(f"   ì¸ì ‘ ê±°ë¦¬ë“¤: {distances}")
            print(f"   split_indices: {split_indices}")
        else:
            split_indices = []
            print(f"   ac={ac}, ac_splits={ac_splits} â†’ split ë¶ˆí•„ìš”")

        # 5. split index ê¸°ì¤€ìœ¼ë¡œ ìˆ«ì ê·¸ë£¹í•‘
        print("5. split index ê¸°ì¤€ ìˆ«ì ê·¸ë£¹í•‘ ì¤‘...")
        digits_grouped = []
        temp_group = []
        for i, (img, coord) in enumerate(sorted(digit_crops, key=lambda t: t[1][0])):
            temp_group.append(img)
            print(f"   [{i}] ì¢Œí‘œ {coord} â†’ temp_groupì— ì¶”ê°€ (í˜„ì¬ ê·¸ë£¹ í¬ê¸°: {len(temp_group)})")
            if i in split_indices:
                digits_grouped.append(temp_group)
                print(f"   âœ‚ï¸  split_index {i}ì—ì„œ ë¶„í• ! â†’ ê·¸ë£¹ {len(digits_grouped)} ìƒì„± (í¬ê¸°: {len(temp_group)})")
                temp_group = []
        if temp_group:
            digits_grouped.append(temp_group)
            print(f"   ğŸ”š ë§ˆì§€ë§‰ ê·¸ë£¹ ì¶”ê°€ â†’ ê·¸ë£¹ {len(digits_grouped)} ìƒì„± (í¬ê¸°: {len(temp_group)})")
        
        print(f"   ìµœì¢… ê·¸ë£¹í•‘ ê²°ê³¼: {len(digits_grouped)}ê°œ ê·¸ë£¹")
        for group_idx, group in enumerate(digits_grouped):
            print(f"     ê·¸ë£¹ [{group_idx}]: {len(group)}ê°œ ìˆ«ì")

        # 6. ëª¨ë¸ì„ í†µí•œ ìˆ«ì ì¸ì‹ ë° ë¬¸ìì—´ ìƒì„±
        print("6. ëª¨ë¸ì„ í†µí•œ ìˆ«ì ì¸ì‹ ë° ë¬¸ìì—´ ìƒì„± ì¤‘...")
        fail_flag = False
        result_string = ""
        confidence_threshold = 0.85  # ì‹ ë¢°ë„ ì„ê³„ê°’ ì„¤ì •
        
        # MNIST ëª¨ë¸ íŒŒì´í”„ë¼ì¸ ê°€ì ¸ì˜¤ê¸°
        pipe = mnist_recognition_pipeline
        
        print(f"   digits_grouped: {len(digits_grouped)}ê°œ ê·¸ë£¹ (ì‹ ë¢°ë„ ì„ê³„ê°’: {confidence_threshold})")
        for group_idx, group in enumerate(digits_grouped):
            print(f"   ê·¸ë£¹ [{group_idx}] ì²˜ë¦¬ ì¤‘: {len(group)}ê°œ ìˆ«ì")
            
            if not pipe:
                print(f"     âŒ MNIST ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤!")
                fail_flag = True
                break
                
            # ê·¸ë£¹ ë‚´ ì´ë¯¸ì§€ë“¤ì„ ìˆ˜í‰ìœ¼ë¡œ ì—°ê²°
            width = sum([img.width for img in group])
            height = max([img.height for img in group])
            new_img = Image.new("L", (width, height), color=255)
            current_x = 0
            for img_idx, img in enumerate(group):
                new_img.paste(img, (current_x, 0))
                print(f"     ìˆ«ì [{img_idx}] ë¶™ì—¬ë„£ê¸°: x={current_x}, í¬ê¸°={img.size}")
                current_x += img.width
            
            print(f"     ì—°ê²°ëœ ì´ë¯¸ì§€ í¬ê¸°: {new_img.size}")
            
            try:
                pred = pipe(new_img)
                if not pred:
                    print(f"     âŒ ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤!")
                    fail_flag = True
                    break
                
                predicted_label = pred[0]['label']
                confidence = pred[0].get('score', 0.0)  # ê¸°ë³¸ê°’ì„ 0.0ìœ¼ë¡œ ì„¤ì •
                
                # ì‹ ë¢°ë„ ì²´í¬
                if confidence < confidence_threshold:
                    print(f"     âŒ ì‹ ë¢°ë„ ë¶€ì¡±: '{predicted_label}' (ì‹ ë¢°ë„: {confidence:.4f} < {confidence_threshold})")
                    fail_flag = True
                    break
                
                print(f"     âœ… ì˜ˆì¸¡ ê²°ê³¼: '{predicted_label}' (ì‹ ë¢°ë„: {confidence:.4f})")
                result_string += predicted_label
                
            except Exception as e:
                print(f"     âŒ ëª¨ë¸ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜: {e}")
                fail_flag = True
                break

        print(f"   ìµœì¢… ê²°ê³¼ ë¬¸ìì—´: '{result_string}' (ì‹¤íŒ¨: {fail_flag})")

        # 7. ê²°ê³¼ ì €ì¥: ì‹¤íŒ¨ ì‹œ base64 ì´ë¯¸ì§€ ì €ì¥, ì„±ê³µ ì‹œ answer ê¸°ë¡
        print("7. ê²°ê³¼ ì €ì¥ ì¤‘...")
        if fail_flag or not result_string:
            print("   ì‹¤íŒ¨ ì¼€ì´ìŠ¤ â†’ failure_jsonì— base64 ì´ë¯¸ì§€ ì €ì¥")
            
            # ì›ë³¸ ì´ë¯¸ì§€ë“¤ì„ ìˆ˜í‰ìœ¼ë¡œ ì—°ê²°
            width = sum([e['img'].width for e in entries_sorted])
            height = max([e['img'].height for e in entries_sorted])
            concat_img = Image.new("RGB", (width, height), color=(255, 255, 255))
            current_x = 0
            for e in entries_sorted:
                concat_img.paste(e['img'], (current_x, 0))
                current_x += e['img'].width

            print(f"     ì—°ê²°ëœ ì‹¤íŒ¨ ì´ë¯¸ì§€ í¬ê¸°: {concat_img.size}")
            
            try:
                buffered = BytesIO()
                concat_img.save(buffered, format="JPEG")
                img_str = base64.b64encode(buffered.getvalue()).decode("utf-8")
                
                failure_reason = "ì‹ ë¢°ë„ ë¶€ì¡±" if fail_flag and result_string else "ì¸ì‹ ë¶ˆê°€"
                failure_entry = {
                    "student_id": student_id,
                    "file_name": "",
                    "base64_data": img_str,  # ì „ì²´ ì €ì¥
                    "question_number": qn,
                    "sub_question_number": sub_qn
                    # "failure_reason": failure_reason  # ì‹¤íŒ¨ ì´ìœ  ì¶”ê°€
                }
                
                failure_json_images.append(failure_entry)
                print(f"     âœ… failure_jsonì— ì¶”ê°€ë¨: Q{qn}-{sub_qn} (ì´ìœ : {failure_reason})")
                
            except Exception as e:
                print(f"     âŒ base64 ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {e}")
        else:
            print(f"   ì„±ê³µ ì¼€ì´ìŠ¤ â†’ answer_jsonì— ë‹µì•ˆ '{result_string}' ì €ì¥")
            
            # answer_jsonì—ì„œ í•´ë‹¹ ë¬¸ì œ ì°¾ì•„ì„œ ë‹µì•ˆ ê¸°ë¡
            found_answer = False
            original_answer = ""
            for a in answer_json_studentAnswers["answers"]:
                if a["question_number"] == qn and a["sub_question_number"] == sub_qn:
                    original_answer = a["student_answer"]  # ê¸°ì¡´ ë‹µì•ˆ ë°±ì—…
                    a["student_answer"] = result_string
                    print(f"     âœ… Q{qn}-{sub_qn}ì— '{result_string}' ì €ì¥ë¨ (ì´ì „: '{original_answer}')")
                    found_answer = True
                    break
            
            if not found_answer:
                print(f"     âš ï¸  Q{qn}-{sub_qn}ì— í•´ë‹¹í•˜ëŠ” answer ìŠ¬ë¡¯ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
                print(f"       ì‚¬ìš© ê°€ëŠ¥í•œ ìŠ¬ë¡¯ë“¤: {[(a['question_number'], a['sub_question_number']) for a in answer_json_studentAnswers['answers'][:5]]}...")

        print("")  # ë¹ˆ ì¤„ ì¶”ê°€

    print(f"ğŸ¯ 2ë‹¨ê³„ ì™„ë£Œ ìš”ì•½:")
    print(f"   - ì²˜ë¦¬ëœ ë¬¸ì œ ìˆ˜: {len(grouped_answers_by_qn_and_subqn)}ê°œ")
    print(f"   - ì´ ì¶”ì¶œëœ ìˆ«ì ì»¨íˆ¬ì–´: {total_digit_crops_count}ê°œ")
    print(f"   - answer_json_studentAnswers ë‹µì•ˆ ìŠ¬ë¡¯: {len(answer_json_studentAnswers['answers'])}ê°œ")
    print(f"   - ì„±ê³µí•œ ë‹µì•ˆ: {sum(1 for a in answer_json_studentAnswers['answers'] if a['student_answer'])}ê°œ")
    print(f"   - ì‹¤íŒ¨í•œ ì´ë¯¸ì§€: {len(failure_json_images)}ê°œ")
    
    # ë‹µì•ˆ ì €ì¥ ìƒíƒœ ì ê²€
    print(f"\nğŸ“Š ë‹µì•ˆ ì €ì¥ ìƒíƒœ ì ê²€:")
    saved_answers = [a for a in answer_json_studentAnswers['answers'] if a['student_answer']]
    empty_answers = [a for a in answer_json_studentAnswers['answers'] if not a['student_answer']]
    
    print(f"   âœ… ì €ì¥ëœ ë‹µì•ˆ ({len(saved_answers)}ê°œ):")
    for a in saved_answers:
        print(f"     Q{a['question_number']}-{a['sub_question_number']}: '{a['student_answer']}'")
    
    if empty_answers:
        print(f"   âŒ ë¹„ì–´ìˆëŠ” ë‹µì•ˆ ({len(empty_answers)}ê°œ):")
        for a in empty_answers[:5]:  # ì²˜ìŒ 5ê°œë§Œ ì¶œë ¥
            print(f"     Q{a['question_number']}-{a['sub_question_number']}: (ë¹„ì–´ìˆìŒ)")
        if len(empty_answers) > 5:
            print(f"     ... ì™¸ {len(empty_answers) - 5}ê°œ")
    
    if failure_json_images:
        print(f"   ğŸ’¥ ì‹¤íŒ¨í•œ ë¬¸ì œë“¤ ({len(failure_json_images)}ê°œ):")
        for fail in failure_json_images:
            reason = fail.get('failure_reason', 'ì•Œ ìˆ˜ ì—†ìŒ')
            print(f"     Q{fail['question_number']}-{fail['sub_question_number']}: {reason}")
    
    # ì„±ê³µë¥  ê³„ì‚°
    success_rate = (len(saved_answers) / len(answer_json_studentAnswers['answers'])) * 100 if answer_json_studentAnswers['answers'] else 0
    print(f"\nğŸ¯ ì „ì²´ ì„±ê³µë¥ : {success_rate:.1f}% ({len(saved_answers)}/{len(answer_json_studentAnswers['answers'])})")
    
    # ì‹ ë¢°ë„ ê¸°ì¤€ìœ¼ë¡œ í•„í„°ë§ëœ ê²°ê³¼ í™•ì¸
    confidence_failures = [f for f in failure_json_images if f.get('failure_reason') == 'ì‹ ë¢°ë„ ë¶€ì¡±']
    if confidence_failures:
        print(f"   ğŸ“‰ ì‹ ë¢°ë„ ë¶€ì¡±ìœ¼ë¡œ ì‹¤íŒ¨: {len(confidence_failures)}ê°œ")
    
    recognition_failures = [f for f in failure_json_images if f.get('failure_reason') == 'ì¸ì‹ ë¶ˆê°€']
    if recognition_failures:
        print(f"   ğŸš« ì¸ì‹ ë¶ˆê°€ë¡œ ì‹¤íŒ¨: {len(recognition_failures)}ê°œ")
    
    # ìµœì¢… ê²°ê³¼ ë¦¬í„´
    return {
        "answer_json": answer_json_studentAnswers,
        "failure_json": failure_json_images
    }

    # return answer_json_studentAnswers, failure_json_images

if __name__ == "__main__":
    # preprocess_answer_sheet í•¨ìˆ˜ í…ŒìŠ¤íŠ¸

    # ì¸ê³µì§€ëŠ¥ ì‹œí—˜ì§€
    # test_original_image_path = '/Users/downy/Documents/2025_DKU_Capstone/2025_DKU_Capstone/AI/test_data/test_answer/32174515.jpg'
    # test_answer_key_json_path = '/Users/downy/Documents/2025_DKU_Capstone/2025_DKU_Capstone/AI/test_data/test_answer.json'

    # ì‹ í˜¸ì™€ ì‹œìŠ¤í…œ ì‹œí—˜ì§€(ìœ ì„ì´ê°€ ì œì‘ 0605)
    test_original_image_path = '/Users/downy/Documents/2025_DKU_Capstone/2025_DKU_Capstone/AI/test_data_signals/ì‹ í˜¸ë°ì‹œìŠ¤í…œ_í•™ìƒë‹µì•ˆì§€ ë° í•™ì ì •ë³´/final_test_image/32208925.jpg'
    test_answer_key_json_path = '/Users/downy/Documents/2025_DKU_Capstone/2025_DKU_Capstone/AI/test_data_signals/test_answer.json'

    print(f"--- Running Preprocessing Test for {test_original_image_path} ---")
    
    # PIL ì´ë¯¸ì§€ë¥¼ ë‹¤ë£¨ê¸° ìœ„í•´ Image import (ì´ë¯¸ ìƒë‹¨ì— ìˆì„ ìˆ˜ ìˆì§€ë§Œ, ëª…ì‹œì ìœ¼ë¡œ í™•ì¸)
    # from PIL import Image # ì´ë¯¸ íŒŒì¼ ìƒë‹¨ì— import ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ì£¼ì„ ì²˜ë¦¬
    # json ëª¨ë“ˆ import (ì´ë¯¸ ìƒë‹¨ì— ìˆì„ ìˆ˜ ìˆì§€ë§Œ, ëª…ì‹œì ìœ¼ë¡œ í™•ì¸)
    # import json # ì´ë¯¸ íŒŒì¼ ìƒë‹¨ì— import ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ì£¼ì„ ì²˜ë¦¬

    processed_crops = preprocess_answer_sheet(test_original_image_path, test_answer_key_json_path)

    if not processed_crops:
        print("Preprocessing returned no crops. Test did not generate any output.")
    else:
        print(f"\nPreprocessing finished. Number of cropped answer regions: {len(processed_crops)}")
        print("Details of processed crops (Key and Image Size):")
        for key, img_obj in processed_crops.items():
            # img_objê°€ PIL Image ê°ì²´ì¸ì§€ í™•ì¸ í›„ size ì†ì„± ì ‘ê·¼
            if hasattr(img_obj, 'size'):
                print(f"  Key: {key}, Image Size: {img_obj.size}")
            else:
                print(f"  Key: {key}, Image Object Type: {type(img_obj)} (Size not available)")

        # --- recognize_answer_sheet_data í•¨ìˆ˜ í…ŒìŠ¤íŠ¸ (1ë‹¨ê³„ê¹Œì§€) ---
        print("\n--- Running Recognition Test (Step 1) --- ")
        # answer_key_data ë¡œë“œ (recognize_answer_sheet_data í•¨ìˆ˜ì— í•„ìš”)
        try:
            with open(test_answer_key_json_path, 'r', encoding='utf-8') as f:
                answer_key_data_for_test = json.load(f)
            
            recognition_step1_result = recognize_answer_sheet_data(processed_crops, answer_key_data_for_test)
            print("\nRecognition Step 1 Result:")
            # ë³´ê¸° ì‰½ê²Œ json.dumpsë¥¼ ì‚¬ìš©í•˜ì—¬ ì¶œë ¥
            print(json.dumps(recognition_step1_result, indent=2, ensure_ascii=False))
        except Exception as e:
            print(f"Error during recognition test (Step 1): {e}")

    print("\n--- Test Script Finished ---")
